"""
6ë‹¨ê³„: ë‹µë³€ ìƒì„± ë¡œì§
"""

import json
import re
import logging
from typing import Dict, List, Tuple
from langchain_core.prompts import ChatPromptTemplate
from models.state import MeetingQAState
from utils.content_filter import detect_content_filter, create_safe_response

logger = logging.getLogger(__name__)

class AnswerGenerator:
    """ë‹µë³€ ìƒì„± í´ë˜ìŠ¤"""
    
    def __init__(self, llm):
        self.llm = llm
    
    def _stabilize_chunks(self, chunks: List[Dict], max_count: int = None) -> List[Dict]:
        """ì²­í¬ë¥¼ ì•ˆì •ì ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ì¼ê´€ì„± í™•ë³´"""
        if not chunks:
            return []
        
        # 1ì°¨: relevance_score ë‚´ë¦¼ì°¨ìˆœ (ë†’ì€ ì ìˆ˜ ìš°ì„ )
        # 2ì°¨: script_id ì˜¤ë¦„ì°¨ìˆœ (ë™ì¼ ì ìˆ˜ì¼ ë•Œ ì¼ê´€ëœ ìˆœì„œ)
        # 3ì°¨: chunk_index ì˜¤ë¦„ì°¨ìˆœ (ë™ì¼ script_idì¼ ë•Œ ì¼ê´€ëœ ìˆœì„œ)
        sorted_chunks = sorted(chunks, 
                              key=lambda x: (
                                  -x.get("relevance_score", 0.0),  # ìŒìˆ˜ë¡œ ë‚´ë¦¼ì°¨ìˆœ
                                  x.get("script_id", ""),          # ì˜¤ë¦„ì°¨ìˆœ
                                  x.get("chunk_index", 0)          # ì˜¤ë¦„ì°¨ìˆœ
                              ))
        
        # ìµœëŒ€ ê°œìˆ˜ ì œí•œ
        if max_count:
            return sorted_chunks[:max_count]
        
        return sorted_chunks

    def _stabilize_summaries(self, summaries: List[Dict], max_count: int = None) -> List[Dict]:
        """ìš”ì•½ë³¸ì„ ì•ˆì •ì ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ì¼ê´€ì„± í™•ë³´"""
        if not summaries:
            return []
        
        # script_idë¡œ ì •ë ¬í•˜ì—¬ ì¼ê´€ëœ ìˆœì„œ ë³´ì¥
        sorted_summaries = sorted(summaries, key=lambda x: x.get("script_id", ""))
        
        # ìµœëŒ€ ê°œìˆ˜ ì œí•œ
        if max_count:
            return sorted_summaries[:max_count]
        
        return sorted_summaries

    def _build_script_metadata(self, original_scripts: List[Dict]) -> Dict[str, Dict]:
        """original_scriptsì—ì„œ script_metadata ë§¤í•‘ ìƒì„± (ì¤‘ë³µ ì œê±°ìš© ìœ í‹¸ë¦¬í‹°)"""
        script_metadata = {}
        for script in original_scripts:
            script_id = script.get("script_id")
            if script_id:
                script_metadata[script_id] = {
                    "title": script.get("title", ""),
                    "meeting_date": script.get("timestamp", "")
                }
        return script_metadata
    
    def _build_context(self, relevant_summaries: List[Dict], relevant_chunks: List[Dict]) -> str:
        """ì»¨í…ìŠ¤íŠ¸ ìƒì„± ë¡œì§ í†µí•© (ì•ˆì •ì ì¸ ì •ë ¬ ì ìš©)"""
        context_parts = []
        
        # ìš”ì•½ë³¸ ì¶”ê°€ (ì•ˆì •ì ì¸ ì •ë ¬)
        stable_summaries = self._stabilize_summaries(relevant_summaries, 3)
        for summary in stable_summaries:
            summary_text = summary.get('summary_text', '').strip()
            if summary_text:
                context_parts.append(f"[ìš”ì•½ë³¸] {summary_text}")
        
        # ì²­í¬ ì¶”ê°€ (ì•ˆì •ì ì¸ ì •ë ¬)
        stable_chunks = self._stabilize_chunks(relevant_chunks, 5)
        for chunk in stable_chunks:
            chunk_text = chunk.get('chunk_text', '').strip()
            if chunk_text:
                context_parts.append(f"[ì›ë³¸] {chunk_text}")
        
        context = "\n\n".join(context_parts)
        
        # ë¹ˆ ì»¨í…ìŠ¤íŠ¸ ì²˜ë¦¬
        if not context.strip():
            return "[ì •ë³´ ì—†ìŒ] ê´€ë ¨ëœ íšŒì˜ë¡ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        return context
    
    def _handle_empty_context(self, question: str) -> Tuple[str, List[Dict]]:
        """ë¹ˆ ì»¨í…ìŠ¤íŠ¸ì¼ ë•Œ ëª…ì‹œì ì¸ ë‹µë³€ ìƒì„±"""
        fallback_answer = f"ì£„ì†¡í•©ë‹ˆë‹¤. '{question}'ì— ëŒ€í•œ ê´€ë ¨ íšŒì˜ë¡ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ì„ ì‹œë„í•´ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤."
        return fallback_answer, []
    
    def _build_sources(self, relevant_chunks: List[Dict]) -> List[Dict]:
        """Sources ìƒì„± (ì•ˆì •ì ì¸ ì •ë ¬ ì ìš©)"""
        if not relevant_chunks:
            return []
        
        # ì•ˆì •ì ì¸ ì •ë ¬ ì ìš©
        stable_chunks = self._stabilize_chunks(relevant_chunks, 5)
        
        # ì¤‘ë³µ ì œê±° (íƒ€ì… ì•ˆì „ì„± ê°•í™”)
        seen_scripts = {}
        for chunk in stable_chunks:
            script_id = chunk.get("script_id")
            if not script_id:
                continue
                
            chunk_index = chunk.get("chunk_index", 0)
            relevance_score = chunk.get("relevance_score", 0.0)
            
            if script_id not in seen_scripts or relevance_score > seen_scripts[script_id]["relevance_score"]:
                seen_scripts[script_id] = {
                    "script_id": script_id,
                    "chunk_index": chunk_index,
                    "relevance_score": relevance_score
                }
        
        return list(seen_scripts.values())
    
    def _calculate_confidence(self, relevant_chunks: List[Dict]) -> float:
        """ì‹ ë¢°ë„ ê³„ì‚° ê°œì„  - ì²­í¬ ê°œìˆ˜ì™€ í’ˆì§ˆ ê³ ë ¤"""
        if not relevant_chunks:
            return 0.1
        
        # ì²­í¬ ê°œìˆ˜ì™€ í‰ê·  ê´€ë ¨ë„ë¥¼ ê³ ë ¤
        chunk_count = len(relevant_chunks)
        top_chunks = relevant_chunks[:3]  # ìƒìœ„ 3ê°œë§Œ ì‚¬ìš©
        
        avg_score = sum(chunk.get("relevance_score", 0.0) for chunk in top_chunks) / len(top_chunks)
        
        # ì²­í¬ ê°œìˆ˜ ë³´ë„ˆìŠ¤ (ìµœëŒ€ 0.2)
        count_bonus = min(0.2, chunk_count * 0.05)
        
        # ìµœì¢… ì‹ ë¢°ë„ ê³„ì‚°
        confidence = min(0.9, max(0.3, avg_score + count_bonus))
        return confidence
    
    def _convert_quotes_to_evidence(self, quotes: List[Dict], relevant_chunks: List[Dict], original_scripts: List[Dict]) -> List[Dict]:
        """êµ¬ì¡°í™”ëœ quotesë¥¼ evidence_quotes í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ì•ˆì •ì ì¸ ì •ë ¬ ì ìš©)"""
        evidence_quotes = []
        
        # script_metadata ë§¤í•‘ ìƒì„±
        script_metadata = self._build_script_metadata(original_scripts)
        
        # ì²­í¬ë¥¼ ì•ˆì •ì ìœ¼ë¡œ ì •ë ¬
        stable_chunks = self._stabilize_chunks(relevant_chunks)
        
        # ì²­í¬ ê²€ìƒ‰ ìµœì í™” - ì¸ë±ìŠ¤ ì‚¬ì „ ìƒì„±
        chunk_text_map = {}
        for chunk in stable_chunks:
            chunk_text = chunk.get("chunk_text", "")
            if chunk_text:
                chunk_text_map[chunk_text] = chunk
        
        # quotesë¥¼ evidence_quotesë¡œ ë³€í™˜ (ìµœì í™”ëœ ê²€ìƒ‰)
        for quote_data in quotes:
            quote_text = quote_data.get("text", "")
            speaker = quote_data.get("speaker", "")
            
            # ë‹¤ë‹¨ê³„ ìœ ì—°í•œ ë§¤ì¹­ ë¡œì§
            source_chunk = None
            matching_method = ""
            
            # 1ë‹¨ê³„: ì •í™•í•œ ë§¤ì¹­
            for chunk_text, chunk in chunk_text_map.items():
                if quote_text in chunk_text:
                    source_chunk = chunk
                    matching_method = "ì •í™•í•œ ë§¤ì¹­"
                    break
            
            # 2ë‹¨ê³„: ì •ê·œí™”ëœ ë§¤ì¹­ (ê³µë°±, íŠ¹ìˆ˜ë¬¸ì ì œê±°)
            if not source_chunk:
                normalized_quote = re.sub(r'[\s\.,!?]+', ' ', quote_text).strip()
                for chunk_text, chunk in chunk_text_map.items():
                    normalized_chunk = re.sub(r'[\s\.,!?]+', ' ', chunk_text).strip()
                    if normalized_quote in normalized_chunk:
                        source_chunk = chunk
                        matching_method = "ì •ê·œí™”ëœ ë§¤ì¹­"
                        break
            
            # 3ë‹¨ê³„: í•µì‹¬ ë‹¨ì–´ ë§¤ì¹­ (ìµœì†Œ 3ë‹¨ì–´)
            if not source_chunk:
                quote_words = normalized_quote.split()
                if len(quote_words) >= 3:
                    for chunk_text, chunk in chunk_text_map.items():
                        normalized_chunk = re.sub(r'[\s\.,!?]+', ' ', chunk_text).strip()
                        # í•µì‹¬ ë‹¨ì–´ë“¤ì´ ëª¨ë‘ í¬í•¨ë˜ëŠ”ì§€ í™•ì¸
                        if all(word in normalized_chunk for word in quote_words[:3]):
                            source_chunk = chunk
                            matching_method = "í•µì‹¬ ë‹¨ì–´ ë§¤ì¹­"
                            break
            
            # 4ë‹¨ê³„: ë¶€ë¶„ ë‹¨ì–´ ë§¤ì¹­ (2ë‹¨ì–´)
            if not source_chunk:
                quote_words = normalized_quote.split()
                if len(quote_words) >= 2:
                    for chunk_text, chunk in chunk_text_map.items():
                        normalized_chunk = re.sub(r'[\s\.,!?]+', ' ', chunk_text).strip()
                        # 2ë‹¨ì–´ ì´ìƒ ë§¤ì¹­ë˜ëŠ”ì§€ í™•ì¸
                        matched_words = sum(1 for word in quote_words if word in normalized_chunk)
                        if matched_words >= 2:
                            source_chunk = chunk
                            matching_method = "ë¶€ë¶„ ë‹¨ì–´ ë§¤ì¹­"
                            break
            
            # 5ë‹¨ê³„: Fallback - ì²« ë²ˆì§¸ ì²­í¬ ì‚¬ìš© (ìµœì†Œí•œì˜ ë©”íƒ€ë°ì´í„°ë¼ë„ ì œê³µ)
            if not source_chunk and stable_chunks:
                source_chunk = stable_chunks[0]
                matching_method = "Fallback (ì²« ë²ˆì§¸ ì²­í¬)"
                logger.warning(f"âš ï¸ ì¸ìš©ë¬¸ ë§¤ì¹­ ì‹¤íŒ¨, Fallback ì‚¬ìš©: '{quote_text[:30]}...'")
            
            # ë§¤ì¹­ ê²°ê³¼ ë¡œê¹…
            if source_chunk:
                logger.debug(f"âœ… ì¸ìš©ë¬¸ ë§¤ì¹­ ì„±ê³µ ({matching_method}): '{quote_text[:30]}...' -> chunk {source_chunk.get('chunk_index', 0)}")
            
            # ë§¤ì¹­ëœ ì²­í¬ê°€ ìˆìœ¼ë©´ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
            if source_chunk:
                script_id = source_chunk.get("script_id", "")
                metadata = script_metadata.get(script_id, {})
                
                evidence_quotes.append({
                    "quote": quote_text,
                    "speaker": speaker,
                    "script_id": script_id,
                    "meeting_title": metadata.get("title", ""),
                    "meeting_date": metadata.get("meeting_date", ""),
                    "chunk_index": source_chunk.get("chunk_index", 0),
                    "relevance_score": source_chunk.get("relevance_score", 0.0)
                })
            else:
                # ìµœí›„ì˜ ìˆ˜ë‹¨: ë¹ˆ ë©”íƒ€ë°ì´í„°ë¡œ ì €ì¥
                evidence_quotes.append({
                    "quote": quote_text,
                    "speaker": speaker,
                    "script_id": "",
                    "meeting_title": "",
                    "meeting_date": "",
                    "chunk_index": 0,
                    "relevance_score": 0.0
                })
                logger.warning(f"âš ï¸ ì¸ìš©ë¬¸ ì™„ì „ ë§¤ì¹­ ì‹¤íŒ¨: '{quote_text[:30]}...'")
        return evidence_quotes
    
    def _generate_structured_answer(self, question: str, context: str, memory: str = "") -> Tuple[str, List[Dict]]:
        """êµ¬ì¡°í™”ëœ JSON ì¶œë ¥ìœ¼ë¡œ ë‹µë³€ ìƒì„±"""
        
        memory_context = f"\n\nì´ì „ ëŒ€í™” ë§¥ë½: {memory}" if memory else ""
        
        structured_prompt = f'''ë‹¹ì‹ ì€ íšŒì˜ë¡ ê¸°ë°˜ QA ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
        íšŒì˜ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ í•´ì„œ ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
        ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.

        {{
            "answer": "íšŒì˜ë¡ ê¸°ë°˜ ìµœì¢… ë‹µë³€ (5ë¬¸ì¥ ì´ë‚´)",
            "quotes": [
                {{"text": "íšŒì˜ë¡ì—ì„œ ì¶”ì¶œí•œ ì¸ìš©ë¬¸", "speaker": "í™”ì01"}},
                {{"text": "ì¶”ê°€ ì¸ìš©ë¬¸", "speaker": "í™”ì02"}}
            ]
        }}

        ì§ˆë¬¸: {question}{memory_context}

        íšŒì˜ë¡ ë‚´ìš©:
        {context}

        JSON:'''

        raw_content = ""
        try:
            # JSON Modeë¡œ ì‘ë‹µ ìƒì„± ì‹œë„
            response = self.llm.invoke(structured_prompt)
            raw_content = response.content.strip()
            
            # JSON íŒŒì‹±
            data = json.loads(raw_content)
            answer = str(data.get("answer", "")) if data.get("answer") else ""
            quotes = data.get("quotes", []) if isinstance(data.get("quotes"), list) else []
            
            # JSON íŒŒì‹±ì´ ì„±ê³µí–ˆìœ¼ë©´ ê²°ê³¼ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ë¹ˆ ê²°ê³¼ë„ ìœ íš¨í•œ ê²°ê³¼)
            logger.debug(f"âœ… JSON íŒŒì‹± ì„±ê³µ: ë‹µë³€ {len(answer)}ì, ì¸ìš©ë¬¸ {len(quotes)}ê°œ")
            return answer, quotes
            
        except json.JSONDecodeError as e:
            logger.warning(f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            return self._simple_fallback_parsing(raw_content)
        except Exception as e:
            logger.error(f"âŒ êµ¬ì¡°í™”ëœ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
            return self._simple_fallback_parsing(raw_content) if raw_content else ("", [])

    def _simple_fallback_parsing(self, raw_content: str) -> Tuple[str, List[Dict]]:
        """JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê°„ë‹¨í•œ ë°±ì—… íŒŒì‹±"""
        
        # ê°„ë‹¨í•œ ì •ê·œì‹ìœ¼ë¡œ ì¸ìš©ë¬¸ë§Œ ì¶”ì¶œ (ìœ ì—°í•œ ê³µë°± ì²˜ë¦¬)
        quote_pattern = r'\(\s*"([^"]+)"\s*,\s*(í™”ì\d+)\s*\)'
        matches = re.findall(quote_pattern, raw_content)
        
        # ì¸ìš©ë¬¸ ì œê±°í•˜ì—¬ ìˆœìˆ˜ ë‹µë³€ ì¶”ì¶œ
        clean_answer = re.sub(quote_pattern, '', raw_content).strip()
        clean_answer = re.sub(r'\n\s*\n', '\n', clean_answer).strip()
        
        # quotes í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        quotes = [{"text": quote, "speaker": speaker} for quote, speaker in matches]
        
        logger.debug(f"ğŸ”„ ë°±ì—… íŒŒì‹± ì™„ë£Œ: ë‹µë³€ {len(clean_answer)}ì, ì¸ìš©ë¬¸ {len(quotes)}ê°œ")
        return clean_answer, quotes

    def generate_final_answer(self, state: MeetingQAState) -> MeetingQAState:
        """7ë‹¨ê³„: ìµœì¢… ë‹µë³€ ìƒì„±"""
        try:
            user_question = state.get("user_question", "")
            relevant_summaries = state.get("relevant_summaries", [])
            relevant_chunks = state.get("relevant_chunks", [])
            conversation_memory = state.get("conversation_memory", "")
            
            if not user_question:
                raise ValueError("ì‚¬ìš©ì ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            
            # ê³µí†µ í•¨ìˆ˜ë¡œ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
            context = self._build_context(relevant_summaries, relevant_chunks)
            
            # ë¹ˆ ì»¨í…ìŠ¤íŠ¸ ì²˜ë¦¬ (ì£¼ìš” ë¬¸ì œ í•´ê²°)
            if "[ì •ë³´ ì—†ìŒ]" in context:
                logger.warning("âš ï¸ ë¹ˆ ì»¨í…ìŠ¤íŠ¸ ê°ì§€ - ëª…ì‹œì  ë‹µë³€ ìƒì„±")
                structured_answer, structured_quotes = self._handle_empty_context(user_question)
            else:
                # ğŸš€ êµ¬ì¡°í™”ëœ JSON ë‹µë³€ ìƒì„± (ìƒˆë¡œìš´ ë°©ì‹!)
                logger.debug("ğŸ”„ êµ¬ì¡°í™”ëœ JSON ë‹µë³€ ìƒì„± ì‹œì‘")
                structured_answer, structured_quotes = self._generate_structured_answer(
                    question=user_question,
                    context=context,
                    memory=conversation_memory
                )
            
            # ê³µí†µ í•¨ìˆ˜ë¡œ evidence_quotes ë³€í™˜
            original_scripts = state.get("original_scripts", [])
            evidence_quotes = self._convert_quotes_to_evidence(structured_quotes, relevant_chunks, original_scripts)
            
            final_answer = structured_answer
            
            # fallback ë©”ì‹œì§€ ì²˜ë¦¬ ì œê±° (ë‹¨ìˆœí•œ ì—ëŸ¬ ì²˜ë¦¬ë¡œ ë³€ê²½)
            
            # ê³µí†µ í•¨ìˆ˜ë¡œ sources ìƒì„± (ë‹¨ìˆœí™”ë¨)
            sources = self._build_sources(relevant_chunks)

            # ì‹¤ì œ ì‚¬ìš©ëœ ë¬¸ì„œ ID ê³„ì‚°
            used_script_ids = sorted({s["script_id"] for s in sources})
            
            # ì‹ ë¢°ë„ ê³„ì‚° (ê°œì„ ë¨ - ì²­í¬ ê°œìˆ˜ì™€ í’ˆì§ˆ ê³ ë ¤)
            confidence_score = self._calculate_confidence(relevant_chunks)
            
            
            # ìµœì¢… ì‘ë‹µ state êµ¬ì„±
            final_state = {
                **state,
                "context_chunks": context.split("\n\n") if context else [],
                "final_answer": final_answer,  # ìˆœìˆ˜ ë‹µë³€ë§Œ
                "evidence_quotes": evidence_quotes,  # ê·¼ê±° ì¸ìš©ë¬¸ë“¤ (ì œëª© ì •ë³´ í¬í•¨)
                "sources": sources,  # ì²­í‚¹ ê´€ë ¨ ì •ë³´ë§Œ
                "used_script_ids": used_script_ids,
                "confidence_score": confidence_score,
                "current_step": "completed"
            }
            
            # ê°„ì†Œí™”ëœ ë¡œê¹… (ìš´ì˜ í™˜ê²½ ìµœì í™”)
            logger.info(f"âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ: ì‹ ë¢°ë„ {confidence_score:.2f}")
            logger.info(f"ğŸ“Š Evidence Quotes: {len(evidence_quotes)}ê°œ, Sources: {len(sources)}ê°œ")
            
            # ìƒì„¸ êµ¬ì¡°ëŠ” DEBUG ë ˆë²¨ë¡œ
            logger.debug(f"ğŸ” ìƒì„¸ êµ¬ì¡°: {json.dumps(final_state, ensure_ascii=False, indent=2)}")
            
            return final_state
            
        except Exception as e:
            logger.error(f"ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            
            # Azure ì½˜í…ì¸  í•„í„° ê°ì§€ (ì˜¤ë¥˜ ì½”ë“œ ìš°ì„ )
            filter_info = detect_content_filter(e)
            if filter_info['is_filtered']:
                logger.warning(f"ë‹µë³€ ìƒì„± ì¤‘ ì½˜í…ì¸  í•„í„° ê°ì§€: {filter_info}")
                return create_safe_response(state, 'generate_answer', filter_info)
            
            # ì¼ë°˜ì ì¸ ì˜¤ë¥˜ ì²˜ë¦¬
            return {
                **state,
                "error_message": f"ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {str(e)}",
                "current_step": "generate_answer_failed"
            }
    
    def improve_answer(self, state: MeetingQAState) -> MeetingQAState:
        """ë‹µë³€ ê°œì„ """
        try:
            question = state.get("processed_question", "")
            current_answer = state.get("final_answer", "")
            quality_score = state.get("answer_quality_score", 0)
            relevant_summaries = state.get("relevant_summaries", [])
            relevant_chunks = state.get("relevant_chunks", [])
            improvement_attempts = int(state.get("improvement_attempts") or 0) + 1
            
            # ê³µí†µ í•¨ìˆ˜ë¡œ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
            context = self._build_context(relevant_summaries, relevant_chunks)
            
            # ê°œì„ ëœ ë‹µë³€ ìƒì„±
            improvement_prompt = f'''ë‹¹ì‹ ì€ íšŒì˜ë¡ ê¸°ë°˜ QA ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
            íšŒì˜ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ í•´ì„œ ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ê°œì„ í•©ë‹ˆë‹¤.
            ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.

            ì´ì „ ë‹µë³€ì˜ í’ˆì§ˆì´ ë‚®ìŠµë‹ˆë‹¤ (ì ìˆ˜: {quality_score}/5). ë” ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ìœ¼ë¡œ ê°œì„ í•´ì£¼ì„¸ìš”.

            **ê°œì„  ê·œì¹™:**
            - ì •í™•ì„±: ì°¸ê³  ìë£Œì— ê¸°ë°˜í•˜ì—¬ ë¶€ì •í™•í•œ ë¶€ë¶„ ìˆ˜ì •
            - ëª…í™•ì„±: ëª¨í˜¸í•œ í‘œí˜„ ì œê±°í•˜ê³  í•µì‹¬ ì •ë³´ ëª…í™•íˆ ì „ë‹¬
            - ê°„ê²°ì„±: 5ë¬¸ì¥ ì´ë‚´ë¡œ ìš”ì•½í•˜ë˜ í•„ìš”í•œ ì •ë³´ëŠ” ëª¨ë‘ í¬í•¨
            - ì¶”ì¸¡ ê¸ˆì§€: ì°¸ê³  ìë£Œì— ì—†ëŠ” ë‚´ìš© ì ˆëŒ€ ì¶”ê°€ ê¸ˆì§€

            ì§ˆë¬¸: {question}
            ì´ì „ ë‹µë³€: {current_answer}
            ì°¸ê³  ìë£Œ:
            {context}

            **ì‘ë‹µ í˜•ì‹ (JSONë§Œ):**
            {{
                "answer": "ê°œì„ ëœ ìˆœìˆ˜ ë‹µë³€ (ì¸ìš©ë¬¸ ì—†ì´)",
                "quotes": [
                    {{"text": "ì¸ìš© ë‚´ìš©", "speaker": "í™”ì01"}},
                    {{"text": "ë‹¤ë¥¸ ì¸ìš© ë‚´ìš©", "speaker": "í™”ì02"}}
                ]
            }}
            '''
            response = self.llm.invoke(improvement_prompt)
            raw_content = response.content.strip()
            
            # JSON íŒŒì‹± ì‹œë„
            try:
                data = json.loads(raw_content)
                improved_answer = data.get("answer", "")
                improved_quotes = data.get("quotes", [])
                
                logger.debug(f"âœ… ê°œì„  ë‹µë³€ JSON íŒŒì‹± ì„±ê³µ: ë‹µë³€ {len(improved_answer)}ì, ì¸ìš©ë¬¸ {len(improved_quotes)}ê°œ")
                
            except json.JSONDecodeError as e:
                logger.warning(f"âš ï¸ ê°œì„  ë‹µë³€ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                improved_answer, improved_quotes = self._simple_fallback_parsing(raw_content)
            except Exception as e:
                logger.error(f"âŒ ê°œì„  ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
                improved_answer, improved_quotes = self._simple_fallback_parsing(raw_content) if raw_content else (current_answer, [])
            
            # ê³µí†µ í•¨ìˆ˜ë¡œ evidence_quotes ë³€í™˜
            original_scripts = state.get("original_scripts", [])
            relevant_chunks = state.get("relevant_chunks", [])
            evidence_quotes = self._convert_quotes_to_evidence(improved_quotes, relevant_chunks, original_scripts)
            
            # ì¼ê´€ëœ ë¡œê¹… í˜•ì‹ ì ìš©
            logger.info(f"âœ… ë‹µë³€ ê°œì„  ì™„ë£Œ: ì‹ ë¢°ë„ ê°œì„  ì˜ˆìƒ")
            logger.info(f"ğŸ“Š Evidence Quotes: {len(evidence_quotes)}ê°œ ìƒì„±")
            
            return {
                **state,
                "final_answer": improved_answer,
                "evidence_quotes": evidence_quotes,
                "improvement_attempts": improvement_attempts,
                "current_step": "answer_improved"
            }
            
        except Exception as e:
            logger.error(f"ë‹µë³€ ê°œì„  ì‹¤íŒ¨: {str(e)}")
            
            # Azure ì½˜í…ì¸  í•„í„° ê°ì§€ (ì˜¤ë¥˜ ì½”ë“œ ìš°ì„ )
            filter_info = detect_content_filter(e)
            if filter_info['is_filtered']:
                logger.warning(f"ë‹µë³€ ê°œì„  ì¤‘ ì½˜í…ì¸  í•„í„° ê°ì§€: {filter_info}")
                safe_response = create_safe_response(state, 'improve_answer', filter_info)
                # improvement_attempts ì¶”ê°€
                safe_response["improvement_attempts"] = int(state.get("improvement_attempts") or 0) + 1
                return safe_response
            
            # ì¼ë°˜ì ì¸ ì˜¤ë¥˜ ì²˜ë¦¬
            return {
                **state,
                "improvement_attempts": int(state.get("improvement_attempts") or 0) + 1,
                "current_step": "improvement_failed"
            }
