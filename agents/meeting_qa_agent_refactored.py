"""
íšŒì˜ë¡ QA Agent - ë¦¬íŒ©í† ë§ëœ ë²„ì „
"""

import logging
from typing import Dict
from langchain_openai import AzureChatOpenAI
from langgraph.graph import StateGraph, END
from config.settings import AZURE_OPENAI_CONFIG
from models.state import MeetingQAState

# ë¶„ë¦¬ëœ ëª¨ë“ˆë“¤ import
from .steps import (
    QuestionProcessor,
    RAGSearchProcessor,
    ScriptFetcher,
    TextProcessor,
    AnswerGenerator,
    QualityEvaluator,
    MemoryManager
)

logger = logging.getLogger(__name__)

class MeetingQAAgent:
    """íšŒì˜ë¡ QA Agent - ë¦¬íŒ©í† ë§ëœ ë²„ì „"""
    
    def __init__(self):
        # LLM ì´ˆê¸°í™”
        self.llm = AzureChatOpenAI(
            api_key=AZURE_OPENAI_CONFIG["api_key"],
            azure_endpoint=AZURE_OPENAI_CONFIG["endpoint"],
            api_version=AZURE_OPENAI_CONFIG["api_version"],
            azure_deployment=AZURE_OPENAI_CONFIG["deployment_name"],
            temperature=1
        )
        
        # ë¶„ë¦¬ëœ ëª¨ë“ˆë“¤ ì´ˆê¸°í™”
        self.question_processor = QuestionProcessor(self.llm)
        self.rag_processor = RAGSearchProcessor()
        self.script_fetcher = ScriptFetcher()
        self.text_processor = TextProcessor()
        self.answer_generator = AnswerGenerator(self.llm)
        self.quality_evaluator = QualityEvaluator(self.llm)
        self.memory_manager = MemoryManager(self.llm)
        
        # ê·¸ëž˜í”„ êµ¬ì„±
        self.graph = self._build_graph()
    
    def _build_graph(self) -> StateGraph:
        """Agent ê·¸ëž˜í”„ êµ¬ì„±"""
        builder = StateGraph(MeetingQAState)
        
        # ë…¸ë“œ ì¶”ê°€
        builder.add_node("summarize_memory", self.memory_manager.summarize_conversation_history)
        builder.add_node("enhance_question", self.question_processor.enhance_question_with_memory)
        builder.add_node("process_question", self.question_processor.process_question)
        builder.add_node("handle_content_filter", self._handle_content_filter)
        builder.add_node("search_rag", self.rag_processor.get_all_rag_summaries)
        builder.add_node("get_specific_summary", self.rag_processor.get_summary_by_id)
        builder.add_node("fetch_scripts", self.script_fetcher.fetch_original_scripts)
        builder.add_node("process_scripts", self.text_processor.process_original_scripts)
        builder.add_node("select_chunks", self.text_processor.select_relevant_chunks)
        builder.add_node("generate_answer", self.answer_generator.generate_final_answer)
        builder.add_node("evaluate_answer", self.quality_evaluator.evaluate_answer_quality)
        builder.add_node("improve_answer", self.answer_generator.improve_answer)
        
        # ì—£ì§€ ì—°ê²°
        builder.set_entry_point("summarize_memory")
        builder.add_edge("summarize_memory", "enhance_question")
        builder.add_edge("enhance_question", "process_question")
        
        # ì¡°ê±´ë¶€ ë¶„ê¸°: process_question â†’ ì½˜í…ì¸  í•„í„° ì²´í¬ ë˜ëŠ” ì¼ë°˜ ì²˜ë¦¬
        builder.add_conditional_edges(
            "process_question",
            self._check_content_filter,  # ì½˜í…ì¸  í•„í„° ì²´í¬ í•¨ìˆ˜
            {
                "content_filter": "handle_content_filter",  # í•„í„° ê°ì§€ ì‹œ
                "normal_flow": "route_rag_search"           # ì •ìƒ ì²˜ë¦¬ ì‹œ
            }
        )
        
        # ì½˜í…ì¸  í•„í„° ì²˜ë¦¬ í›„ ì¢…ë£Œ
        builder.add_edge("handle_content_filter", END)
        
        # ê°€ìƒ ë…¸ë“œë¥¼ í†µí•œ RAG ê²€ìƒ‰ ë¶„ê¸°
        builder.add_node("route_rag_search", self._route_rag_search_node)
        builder.add_conditional_edges(
            "route_rag_search",
            self._route_rag_search,  # ë¶„ê¸° ë¡œì§ í•¨ìˆ˜
            {
                "general_search": "search_rag",           # ì „ì²´ RAG ê²€ìƒ‰
                "specific_search": "get_specific_summary" # íŠ¹ì • ìŠ¤í¬ë¦½íŠ¸ ê²€ìƒ‰
            }
        )
        builder.add_edge("search_rag", "fetch_scripts")
        # get_specific_summary í›„ ë¬¸ì„œ ì—†ìŒ ì²˜ë¦¬
        builder.add_conditional_edges(
            "get_specific_summary",
            self._check_document_found,
            {
                "document_not_found": END,  # ë¬¸ì„œ ì—†ìŒ ì‹œ ì¦‰ì‹œ ì¢…ë£Œ
                "document_found": "fetch_scripts"  # ë¬¸ì„œ ìžˆìŒ ì‹œ ê³„ì†
            }
        )
        builder.add_edge("fetch_scripts", "process_scripts")
        builder.add_edge("process_scripts", "select_chunks")
        builder.add_edge("select_chunks", "generate_answer")
        
        # generate_answer í›„ ì½˜í…ì¸  í•„í„° ì²´í¬
        builder.add_conditional_edges(
            "generate_answer",
            self._check_content_filter_after_generation,
            {
                "content_filter": END,  # í•„í„° ê°ì§€ ì‹œ ì¦‰ì‹œ ì¢…ë£Œ
                "normal_flow": "evaluate_answer"  # ì •ìƒ ì²˜ë¦¬ ì‹œ í’ˆì§ˆ í‰ê°€
            }
        )
        
        # ì¡°ê±´ë¶€ ì—£ì§€ (í’ˆì§ˆ í‰ê°€ í›„)
        builder.add_conditional_edges(
            "evaluate_answer",
            self.quality_evaluator.should_improve_answer,
            {
                "improve": "improve_answer",
                "finish": END
            }
        )
        
        # improve_answer í›„ ì½˜í…ì¸  í•„í„° ì²´í¬
        builder.add_conditional_edges(
            "improve_answer",
            self._check_content_filter_after_generation,
            {
                "content_filter": END,  # í•„í„° ê°ì§€ ì‹œ ì¦‰ì‹œ ì¢…ë£Œ
                "normal_flow": END      # ì •ìƒ ì²˜ë¦¬ ì‹œ ì¢…ë£Œ
            }
        )
        
        return builder.compile()
    
    def _check_content_filter(self, state: MeetingQAState) -> str:
        """ì½˜í…ì¸  í•„í„° ê°ì§€ ì²´í¬ (ì§ˆë¬¸ ì²˜ë¦¬ ë‹¨ê³„)"""
        if state.get("content_filter_triggered", False):
            return "content_filter"
        else:
            return "normal_flow"
    
    def _check_content_filter_after_generation(self, state: MeetingQAState) -> str:
        """ì½˜í…ì¸  í•„í„° ê°ì§€ ì²´í¬ (ë‹µë³€ ìƒì„± í›„)"""
        current_step = state.get("current_step", "")
        
        # ë‹µë³€ ìƒì„± ë˜ëŠ” ê°œì„  ì¤‘ ì½˜í…ì¸  í•„í„° ê°ì§€ ì‹œ
        if (state.get("content_filter_triggered", False) or 
            current_step in ["content_filter_in_answer", "content_filter_in_improvement"]):
            logger.info("ì½˜í…ì¸  í•„í„°ê°€ ê°ì§€ë˜ì–´ ì•ˆì „ ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤.")
            return END  # â† ENDë¡œ ë³€ê²½
        else:
            return "normal_flow"
    
    def _check_document_found(self, state: MeetingQAState) -> str:
        """ë¬¸ì„œ ì¡´ìž¬ ì—¬ë¶€ í™•ì¸"""
        current_step = state.get("current_step", "")
        
        if current_step == "document_not_found":
            logger.info("ìš”ì²­ëœ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return "document_not_found"
        else:
            return "document_found"
    
    def _handle_content_filter(self, state: MeetingQAState) -> MeetingQAState:
        """ì½˜í…ì¸  í•„í„° ê°ì§€ ì‹œ ì•ˆì „ ì‘ë‹µ ìƒì„±"""
        logger.warning("ì½˜í…ì¸  í•„í„°ê°€ ê°ì§€ë˜ì–´ ì•ˆì „ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.")
        
        return {
            **state,
            "final_answer": "Azure ì½˜í…ì¸  í•„í„°ì— ë”°ë¼ í•´ë‹¹ ë‚´ìš©ì˜ ë‹µì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            "sources": [],
            "confidence_score": 0.0,
            "used_script_ids": [],
            "current_step": "content_filter_handled"
        }
    
    def _route_rag_search_node(self, state: MeetingQAState) -> MeetingQAState:
        """RAG ê²€ìƒ‰ ë¶„ê¸°ë¥¼ ìœ„í•œ ê°€ìƒ ë…¸ë“œ (ìƒíƒœ ê·¸ëŒ€ë¡œ ì „ë‹¬)"""
        return state
    
    def _route_rag_search(self, state: MeetingQAState) -> str:
        """RAG ê²€ìƒ‰ ë°©ì‹ ë¶„ê¸° - ë‹¨ìˆœí•œ ë¦¬ìŠ¤íŠ¸ ì²´í¬"""
        user_selected_script_ids = state.get("user_selected_script_ids", [])
        
        # ðŸ” ë¶„ê¸° ë¡œì§ ë””ë²„ê¹…
        logger.info(f"ðŸ” [DEBUG] RAG ê²€ìƒ‰ ë¶„ê¸° ê²°ì •:")
        logger.info(f"ðŸ” [DEBUG] - user_selected_script_ids: {user_selected_script_ids}")
        logger.info(f"ðŸ” [DEBUG] - user_selected_script_ids length: {len(user_selected_script_ids) if user_selected_script_ids else 0}")
        
        if user_selected_script_ids:  # ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ìžˆì§€ ì•Šìœ¼ë©´
            logger.info(f"ðŸ” [DEBUG] - ë¶„ê¸° ê²°ì •: specific_search (ìƒì„¸ ì±—ë´‡)")
            return "specific_search"  # ìƒì„¸ ì±—ë´‡
        else:
            logger.info(f"ðŸ” [DEBUG] - ë¶„ê¸° ê²°ì •: general_search (ê¸°ë³¸ ì±—ë´‡)")
            return "general_search"   # ê¸°ë³¸ ì±—ë´‡
    
    async def run(self, initial_state: MeetingQAState) -> MeetingQAState:
        """Agent ì‹¤í–‰"""
        try:
            logger.info("Meeting QA Agent ì‹¤í–‰ ì‹œìž‘")
            final_state = await self.graph.ainvoke(initial_state)
            logger.info("Meeting QA Agent ì‹¤í–‰ ì™„ë£Œ")
            return final_state
        except Exception as e:
            logger.error(f"Agent ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")
            return {
                **initial_state,
                "error_message": f"Agent ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}",
                "current_step": "failed"
            }
