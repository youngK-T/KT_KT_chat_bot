#!/usr/bin/env python3
"""
í„°ë¯¸ë„ ê¸°ë°˜ Agent í…ŒìŠ¤íŠ¸
"""

import logging
from typing import TypedDict, List, Optional, Literal
from langchain_openai import AzureChatOpenAI
from langgraph.graph import StateGraph, END 
from utils.text_processing import chunk_text, clean_text
from utils.embeddings import EmbeddingManager, find_most_relevant_chunks
from config.settings import AZURE_OPENAI_CONFIG, DEFAULT_CHUNK_SIZE, DEFAULT_CHUNK_OVERLAP

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class TestMeetingQAState(TypedDict, total=False):
    user_question: str
    processed_question: str
    original_scripts: List[dict]
    chunked_scripts: List[dict]
    relevant_chunks: List[dict]
    final_answer: str
    answer_quality_score: int
    improvement_attempts: int
    current_step: str
    error_message: str

class TestAgent:
    def __init__(self):
        self.llm = AzureChatOpenAI(
            deployment_name=AZURE_OPENAI_CONFIG["deployment_name"],
            api_version=AZURE_OPENAI_CONFIG["api_version"],
            azure_endpoint=AZURE_OPENAI_CONFIG["endpoint"],
            api_key=AZURE_OPENAI_CONFIG["api_key"]
        )
        self.embedding_manager = EmbeddingManager()
        self.user_scripts = []
        
        # Agent ê·¸ë˜í”„ êµ¬ì„±
        self.graph = self._build_graph()
    
    def _build_graph(self) -> StateGraph:
        """Agent ê·¸ë˜í”„ êµ¬ì„±"""
        builder = StateGraph(TestMeetingQAState)
        
        # ë…¸ë“œ ì¶”ê°€
        builder.add_node("process_question", self.process_question)
        builder.add_node("load_user_scripts", self.load_user_scripts)
        builder.add_node("process_scripts", self.process_original_scripts)
        builder.add_node("select_chunks", self.select_relevant_chunks)
        builder.add_node("generate_answer", self.generate_final_answer)
        builder.add_node("evaluate_answer", self.evaluate_answer_quality)
        builder.add_node("improve_answer", self.improve_answer)
        
        # ì—£ì§€ ì—°ê²°
        builder.set_entry_point("process_question")
        builder.add_edge("process_question", "load_user_scripts")
        builder.add_edge("load_user_scripts", "process_scripts")
        builder.add_edge("process_scripts", "select_chunks")
        builder.add_edge("select_chunks", "generate_answer")
        builder.add_edge("generate_answer", "evaluate_answer")
        
        
        # ì¡°ê±´ë¶€ ì—£ì§€ (ë”•ì…”ë„ˆë¦¬ ë§¤í•‘ê³¼ í•¨ê»˜)
        builder.add_conditional_edges(
            "evaluate_answer",
            self.should_improve_answer,
            {
                "improve": "improve_answer",
                "finish": END
            }
        )
        builder.add_edge("improve_answer", END)        
        
        return builder.compile()
    
    def add_script(self, content: str, title: str = ""):
        """ìŠ¤í¬ë¦½íŠ¸ ì¶”ê°€"""
        script_data = {
            "meeting_id": f"script_{len(self.user_scripts) + 1}",
            "content": content,
            "filename": f"{title or f'ìŠ¤í¬ë¦½íŠ¸_{len(self.user_scripts) + 1}'}.txt"
        }
        self.user_scripts.append(script_data)
        print(f"âœ… ìŠ¤í¬ë¦½íŠ¸ ì¶”ê°€: {title or f'ìŠ¤í¬ë¦½íŠ¸ {len(self.user_scripts)}'}")
    
    def process_question(self, state: TestMeetingQAState) -> TestMeetingQAState:
        """1ë‹¨ê³„: ì§ˆë¬¸ ì „ì²˜ë¦¬"""
        print("ğŸ” 1ë‹¨ê³„: ì§ˆë¬¸ ì „ì²˜ë¦¬")
        user_question = state.get("user_question", "")
        
        if not user_question:
            return {**state, "error_message": "ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.", "current_step": "process_question_failed"}
        
        processed_question = clean_text(user_question)
        return {**state, "processed_question": processed_question, "current_step": "question_processed"}
    
    def load_user_scripts(self, state: TestMeetingQAState) -> TestMeetingQAState:
        """2ë‹¨ê³„: ì‚¬ìš©ì ìŠ¤í¬ë¦½íŠ¸ ë¡œë“œ"""
        print("ğŸ“ 2ë‹¨ê³„: ì‚¬ìš©ì ìŠ¤í¬ë¦½íŠ¸ ë¡œë“œ")
        print(f"   ë“±ë¡ëœ ìŠ¤í¬ë¦½íŠ¸: {len(self.user_scripts)}ê°œ")
        
        if not self.user_scripts:
            return {**state, "error_message": "ë“±ë¡ëœ ìŠ¤í¬ë¦½íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.", "current_step": "load_scripts_failed"}
        
        return {**state, "original_scripts": self.user_scripts, "current_step": "user_scripts_loaded"}
    
    def process_original_scripts(self, state: TestMeetingQAState) -> TestMeetingQAState:
        """3ë‹¨ê³„: ì›ë³¸ ìŠ¤í¬ë¦½íŠ¸ ì²­í‚¹ ë° ì„ë² ë”©"""
        print("âš™ï¸ 3ë‹¨ê³„: ìŠ¤í¬ë¦½íŠ¸ ì²­í‚¹ ë° ì„ë² ë”©")
        original_scripts = state.get("original_scripts", [])
        
        all_chunked_scripts = []
        for script in original_scripts:
            content = script.get("content", "")
            meeting_id = script.get("meeting_id", "")
            
            chunks = chunk_text(content, DEFAULT_CHUNK_SIZE, DEFAULT_CHUNK_OVERLAP)
            print(f"   {meeting_id}: {len(chunks)}ê°œ ì²­í¬ ìƒì„±")
            
            for i, chunk in enumerate(chunks):
                try:
                    chunk_text_content = chunk["chunk_text"]
                    embedding = self.embedding_manager.embed_query(chunk_text_content)
                    all_chunked_scripts.append({
                        "meeting_id": meeting_id,
                        "chunk_text": chunk_text_content,
                        "chunk_index": i,
                        "chunk_embedding": embedding
                    })
                except Exception as e:
                    print(f"   âŒ ì„ë² ë”© ì‹¤íŒ¨: {e}")
                    return {**state, "chunked_scripts": [], "current_step": "scripts_processing_failed"}
        
        print(f"   ì´ {len(all_chunked_scripts)}ê°œ ì²­í¬ ìƒì„±")
        return {**state, "chunked_scripts": all_chunked_scripts, "current_step": "scripts_processed"}
    
    def select_relevant_chunks(self, state: TestMeetingQAState) -> TestMeetingQAState:
        """4ë‹¨ê³„: ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì²­í¬ ì„ ë³„"""
        print("ğŸ¯ 4ë‹¨ê³„: ê´€ë ¨ ì²­í¬ ì„ ë³„")
        processed_question = state.get("processed_question", "")
        chunked_scripts = state.get("chunked_scripts", [])
        
        try:
            query_embedding = self.embedding_manager.embed_query(processed_question)
            relevant_chunks = find_most_relevant_chunks(
                query_embedding=query_embedding,
                chunks=chunked_scripts,
                top_k=5,
                similarity_threshold=0.6
            )
            print(f"   {len(relevant_chunks)}ê°œ ê´€ë ¨ ì²­í¬ ì„ ë³„")
            return {**state, "relevant_chunks": relevant_chunks, "current_step": "chunks_selected"}
        except Exception as e:
            print(f"   âŒ ì²­í¬ ì„ ë³„ ì‹¤íŒ¨: {e}")
            return {**state, "error_message": f"ì²­í¬ ì„ ë³„ ì‹¤íŒ¨: {e}", "current_step": "select_chunks_failed"}
    
    def generate_final_answer(self, state: TestMeetingQAState) -> TestMeetingQAState:
        """5ë‹¨ê³„: ìµœì¢… ë‹µë³€ ìƒì„±"""
        print("ğŸ¤– 5ë‹¨ê³„: ë‹µë³€ ìƒì„±")
        question = state.get("processed_question", "")
        relevant_chunks = state.get("relevant_chunks", [])
        
        context = "\n\n".join([chunk["chunk_text"] for chunk in relevant_chunks])
        
        prompt = f"""
        ë‹¤ìŒ íšŒì˜ë¡ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.
        
        ì§ˆë¬¸: {question}
        
        ì°¸ê³  ìë£Œ:
        {context}
        
        ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
        """
        
        try:
            response = self.llm.invoke(prompt)
            answer = response.content.strip()
            print(f"   ë‹µë³€ ìƒì„± ì™„ë£Œ")
            return {**state, "final_answer": answer, "current_step": "answer_generated"}
        except Exception as e:
            print(f"   âŒ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
            return {**state, "error_message": f"ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}", "current_step": "generate_answer_failed"}
    
    def evaluate_answer_quality(self, state: TestMeetingQAState) -> TestMeetingQAState:
        """6ë‹¨ê³„: ë‹µë³€ í’ˆì§ˆ í‰ê°€"""
        print("ğŸ“Š 6ë‹¨ê³„: ë‹µë³€ í’ˆì§ˆ í‰ê°€")
        answer = state.get("final_answer", "")
        improvement_attempts = state.get("improvement_attempts", 0)
        
        if not answer:
            return {**state, "answer_quality_score": 5, "current_step": "quality_evaluated"}
        
        try:
            evaluation_prompt = f"""
            ë‹¤ìŒ ë‹µë³€ì˜ í’ˆì§ˆì„ 1-5ì ìœ¼ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”.
            
            ë‹µë³€: {answer}
            
            ì ìˆ˜ë§Œ ìˆ«ìë¡œ ë‹µë³€í•´ì£¼ì„¸ìš” (ì˜ˆ: 4)
            """
            
            response = self.llm.invoke(evaluation_prompt)
            score_text = response.content.strip()
            digits = "".join(ch for ch in score_text if ch.isdigit())
            quality_score = int(digits) if digits else 5
            quality_score = max(1, min(5, quality_score))
            
            print(f"   í’ˆì§ˆ ì ìˆ˜: {quality_score}/5")
            return {**state, "answer_quality_score": quality_score, "improvement_attempts": improvement_attempts, "current_step": "quality_evaluated"}
        except Exception as e:
            print(f"   âŒ í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨: {e}")
            return {**state, "answer_quality_score": 5, "current_step": "quality_evaluation_failed"}
    
    def should_improve_answer(self, state: TestMeetingQAState) -> Literal["improve", "finish"]:
        """ë‹µë³€ ê°œì„  ì—¬ë¶€ ê²°ì •"""
        score = state.get("answer_quality_score", 5)
        tries = state.get("improvement_attempts", 0)
        return "finish" if tries >= 1 or score > 3 else "improve"
    
    def improve_answer(self, state: TestMeetingQAState) -> TestMeetingQAState:
        """7ë‹¨ê³„: ë‹µë³€ ê°œì„ """
        print("ğŸ”„ 7ë‹¨ê³„: ë‹µë³€ ê°œì„ ")
        question = state.get("processed_question", "")
        current_answer = state.get("final_answer", "")
        relevant_chunks = state.get("relevant_chunks", [])
        
        improvement_attempts = state.get("improvement_attempts", 0) + 1
        context = "\n\n".join([chunk["chunk_text"] for chunk in relevant_chunks])
        
        improvement_prompt = f"""
        ë‹¤ìŒ ë‹µë³€ì„ ë” ì •í™•í•˜ê³  ìœ ìš©í•˜ê²Œ ê°œì„ í•´ì£¼ì„¸ìš”.
        
        ì§ˆë¬¸: {question}
        í˜„ì¬ ë‹µë³€: {current_answer}
        
        ì°¸ê³  ìë£Œ:
        {context}
        
        ê°œì„ ëœ ë‹µë³€ì„ ìƒì„±í•´ì£¼ì„¸ìš”.
        """
        
        try:
            response = self.llm.invoke(improvement_prompt)
            improved_answer = response.content.strip()
            print("   ë‹µë³€ ê°œì„  ì™„ë£Œ")
            return {**state, "final_answer": improved_answer, "improvement_attempts": improvement_attempts, "current_step": "answer_improved"}
        except Exception as e:
            print(f"   âŒ ë‹µë³€ ê°œì„  ì‹¤íŒ¨: {e}")
            return {**state, "improvement_attempts": improvement_attempts, "answer_quality_score": 5, "current_step": "answer_improvement_failed"}
    
    def run_agent(self, question: str):
        """Agent ì‹¤í–‰"""
        initial_state = {"user_question": question, "current_step": "started", "improvement_attempts": 0}
        try:
            result = self.graph.invoke(initial_state, config={"recursion_limit": 100})
            if result is None:
                print("âŒ Agent ì‹¤í–‰ ê²°ê³¼ê°€ Noneì…ë‹ˆë‹¤.")
                return
            
            print(f"âœ… ìµœì¢… ë‹¨ê³„: {result.get('current_step')}, ì‹œë„: {result.get('improvement_attempts')}, ì ìˆ˜: {result.get('answer_quality_score')}")
            print(f"ğŸ¤– ìµœì¢… ë‹µë³€: {result.get('final_answer','')}")
        except Exception as e:
            print(f"âŒ run_agent ì˜ˆì™¸: {e}")

def main():
    print("ğŸ¤– í„°ë¯¸ë„ ê¸°ë°˜ Agent í…ŒìŠ¤íŠ¸")
    print("=" * 40)
    
    agent = TestAgent()
    
    # í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì¶”ê°€
    test_script = """
    ì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ì€ 2024ë…„ 1ì›” ì •ê¸° íšŒì˜ì…ë‹ˆë‹¤.
    
    ì£¼ìš” ì•ˆê±´:
    1. 2023ë…„ ì‚¬ì—… ì‹¤ì  ê²€í† 
    2. 2024ë…„ ì‚¬ì—… ê³„íš ìˆ˜ë¦½
    3. ì‹ ê·œ í”„ë¡œì íŠ¸ ì¶”ì§„ ë°©ì•ˆ
    4. ì˜ˆì‚° í¸ì„± ê³„íš
    
    ë¨¼ì € 2023ë…„ ì‚¬ì—… ì‹¤ì ì„ ê²€í† í•´ë³´ê² ìŠµë‹ˆë‹¤.
    ë§¤ì¶œì€ ì „ë…„ ëŒ€ë¹„ 15% ì¦ê°€í–ˆìœ¼ë©°, ì‹ ê·œ ê³ ê° í™•ë³´ì— ì„±ê³µí–ˆìŠµë‹ˆë‹¤.
    
    2024ë…„ì—ëŠ” AI ê¸°ìˆ  ë„ì…ì„ í†µí•œ ì—…ë¬´ íš¨ìœ¨ì„± í–¥ìƒì— ì§‘ì¤‘í•˜ê² ìŠµë‹ˆë‹¤.
    ì±—ë´‡ ê°œë°œ í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰ ì¤‘ì´ë©°, í˜„ì¬ 80% ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.
    """
    
    agent.add_script(test_script, "2024ë…„ 1ì›” íšŒì˜ë¡")
    
    # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸
    test_question = "ì£¼ìš” ì•ˆê±´ì€ ë¬´ì—‡ì¸ê°€ìš”?"
    agent.run_agent(test_question)

if __name__ == "__main__":
    main()